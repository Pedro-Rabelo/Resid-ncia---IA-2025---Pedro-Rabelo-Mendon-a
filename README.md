# MTCNN - Multi-task Cascaded Convolutional Networks

ImplementaÃ§Ã£o completa e detalhada do MTCNN em PyTorch para detecÃ§Ã£o facial e localizaÃ§Ã£o de landmarks.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Requisitos](#requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [PreparaÃ§Ã£o dos Dados](#preparaÃ§Ã£o-dos-dados)
- [Treinamento](#treinamento)
- [InferÃªncia](#inferÃªncia)
- [Detalhes TÃ©cnicos](#detalhes-tÃ©cnicos)
- [Resultados Esperados](#resultados-esperados)

---

## ğŸ¯ VisÃ£o Geral

O MTCNN Ã© uma arquitetura em cascata com trÃªs redes neurais convolucionais (P-Net, R-Net, O-Net) que trabalham em conjunto para:

1. **Detectar faces** em diferentes escalas
2. **Refinar detecÃ§Ãµes** progressivamente
3. **Localizar 5 landmarks faciais** (olhos, nariz, cantos da boca)

### Principais CaracterÃ­sticas

âœ… **Arquitetura em Cascata**: TrÃªs estÃ¡gios progressivos (coarse-to-fine)  
âœ… **Aprendizado Multi-tarefa**: ClassificaÃ§Ã£o + RegressÃ£o de BBox + Landmarks  
âœ… **Online Hard Sample Mining**: Foco automÃ¡tico em amostras difÃ­ceis  
âœ… **Tempo Real**: 99 fps em GPU, 16 fps em CPU  

---

## ğŸ’» Requisitos

### Software
```bash
Python >= 3.8
PyTorch >= 2.0.0
CUDA >= 11.0 (opcional)
```

---

## ğŸ“ Estrutura do Projeto

```
MTCNN/
â”œâ”€â”€ config.py                    # ConfiguraÃ§Ãµes globais
â”œâ”€â”€ main.py                      # Script principal
â”œâ”€â”€ requirements.txt             # DependÃªncias
â”‚
â”œâ”€â”€ models/                      # Arquiteturas das redes
â”‚   â”œâ”€â”€ pnet.py                 # Proposal Network
â”‚   â”œâ”€â”€ rnet.py                 # Refinement Network
â”‚   â””â”€â”€ onet.py                 # Output Network
â”‚
â”œâ”€â”€ utils/                       # UtilitÃ¡rios
â”‚   â”œâ”€â”€ bbox_utils.py           # NMS, IoU, calibraÃ§Ã£o
â”‚   â”œâ”€â”€ data_utils.py           # Dataset e parsers
â”‚   â””â”€â”€ image_utils.py          # Processamento de imagens
â”‚
â”œâ”€â”€ data_preprocessing/          # GeraÃ§Ã£o de dados
â”‚   â”œâ”€â”€ generate_pnet_data.py
â”‚   â”œâ”€â”€ generate_rnet_data.py
â”‚   â””â”€â”€ generate_onet_data.py
â”‚
â”œâ”€â”€ training/                    # Scripts de treinamento
â”‚   â”œâ”€â”€ train_pnet.py
â”‚   â”œâ”€â”€ train_rnet.py
â”‚   â”œâ”€â”€ train_onet.py
â”‚   â””â”€â”€ hard_sample_mining.py
â”‚
â”œâ”€â”€ inference/                   # DetecÃ§Ã£o
â”‚   â”œâ”€â”€ detector.py             # Detector completo
â”‚   â””â”€â”€ visualization.py        # VisualizaÃ§Ã£o
â”‚
â”œâ”€â”€ data/                        # Dados
â”‚   â”œâ”€â”€ raw/                    # Datasets originais
â”‚   â”‚   â”œâ”€â”€ WIDER_FACE/
â”‚   â”‚   â””â”€â”€ CelebA/
â”‚   â””â”€â”€ processed/              # Dados processados
â”‚       â”œâ”€â”€ pnet/
â”‚       â”œâ”€â”€ rnet/
â”‚       â””â”€â”€ onet/
â”‚
â””â”€â”€ checkpoints/                 # Modelos treinados
    â”œâ”€â”€ pnet/
    â”œâ”€â”€ rnet/
    â””â”€â”€ onet/
```

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio
```bash
git clone <seu-repositorio>
cd mtcnn_project
```

### 2. Instale DependÃªncias
```bash
pip install -r requirements.txt
```

### 3. Crie Estrutura de DiretÃ³rios
```bash
python config.py
```

---

## ğŸ“¦ PreparaÃ§Ã£o dos Dados

### 1. Download dos Datasets

#### WIDER FACE
```bash
# Download
wget http://shuoyang1213.me/WIDERFACE/WiderFace_BBXT.v2.tar.gz
wget http://shuoyang1213.me/WIDERFACE/WIDER_train.zip

# Extrair
tar -xzf WiderFace_BBXT.v2.tar.gz -C data/raw/WIDER_FACE/
unzip WIDER_train.zip -d data/raw/WIDER_FACE/
```

#### CelebA (Opcional, para landmarks)
```bash
# Download do Google Drive ou Kaggle
# Estrutura esperada:
data/raw/CelebA/
â”œâ”€â”€ img_celeba/          # Imagens
â””â”€â”€ list_landmarks_celeba.txt  # AnotaÃ§Ãµes
```

### 2. Gerar Dados de Treinamento

#### P-Net Data
```bash
python main.py --mode prepare --stage pnet
```

**O que acontece:**
- Processa ~12,000 imagens do WIDER FACE
- Gera ~250,000 samples:
  - Negatives: ~100,000
  - Positives: ~70,000
  - Part faces: ~50,000
  - Landmarks: ~30,000
- Salva crops 12x12 em `data/processed/pnet/`
- Cria `pnet_train.txt` com anotaÃ§Ãµes

**Tempo estimado:** 2-4 horas

---

## ğŸ‹ï¸ Treinamento

### Pipeline Sequencial

O treinamento segue uma **ordem especÃ­fica** pois cada rede usa outputs das anteriores:

```
1. Treinar P-Net
2. Gerar dados R-Net usando P-Net
3. Treinar R-Net
4. Gerar dados O-Net usando P-Net + R-Net
5. Treinar O-Net
```

### 1. Treinar P-Net

```bash
python main.py --mode train --stage pnet
```

**ConfiguraÃ§Ãµes (config.py):**
```python
PNET_INPUT_SIZE = 12
PNET_BATCH_SIZE = 512
PNET_EPOCHS = 30
PNET_LR = 0.001
PNET_CLS_WEIGHT = 1.0
PNET_BOX_WEIGHT = 0.5
PNET_LANDMARK_WEIGHT = 0.5
```

**Hard Sample Mining:**
- Ativado por padrÃ£o
- Ratio: 70% (top 70% das losses)
- AtualizaÃ§Ã£o online a cada batch

**Monitoramento:**
```bash
tensorboard --logdir runs/pnet
```

**Tempo estimado:** 4-6 horas (GPU), 20-24 horas (CPU)

### 2. Gerar Dados R-Net

```bash
python main.py --mode prepare --stage rnet
```

**O que acontece:**
- Carrega P-Net treinado
- Detecta faces em imagens do WIDER FACE
- Coleta detecÃ§Ãµes 24x24
- Gera `rnet_train.txt`

**Tempo estimado:** 3-5 horas

### 3. Treinar R-Net

```bash
python main.py --mode train --stage rnet
```

**ConfiguraÃ§Ãµes:**
```python
RNET_INPUT_SIZE = 24
RNET_BATCH_SIZE = 256
RNET_EPOCHS = 25
RNET_LR = 0.001
```

**Tempo estimado:** 3-5 horas (GPU)

### 4. Gerar Dados O-Net

```bash
python main.py --mode prepare --stage onet
```

**Tempo estimado:** 4-6 horas

### 5. Treinar O-Net

```bash
python main.py --mode train --stage onet
```

**ConfiguraÃ§Ãµes:**
```python
ONET_INPUT_SIZE = 48
ONET_BATCH_SIZE = 128
ONET_EPOCHS = 25
ONET_LR = 0.001
ONET_LANDMARK_WEIGHT = 1.0  # Peso MAIOR para landmarks
```

**Tempo estimado:** 4-6 horas (GPU)

### Pipeline Completo Automatizado

```bash
python main.py --mode full
```

**âš ï¸ AtenÃ§Ã£o:** Este comando executa TODO o pipeline sequencialmente.  
**Tempo total estimado:** 24-48 horas (depende do hardware)

---

## ğŸ” InferÃªncia

### DetecÃ§Ã£o em Uma Imagem

```bash
python main.py --mode detect --image path/to/image.jpg --output result.jpg
```

### Uso ProgramÃ¡tico

```python
from inference.detector import MTCNNDetector
import cv2

# Inicializar detector
detector = MTCNNDetector(
    pnet_path='checkpoints/pnet/pnet_final.pth',
    rnet_path='checkpoints/rnet/rnet_final.pth',
    onet_path='checkpoints/onet/onet_final.pth'
)

# Carregar imagem
image = cv2.imread('test.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Detectar
bboxes, scores, landmarks = detector.detect_faces(image_rgb, min_face_size=20)

print(f"Detectadas {len(bboxes)} faces")
# bboxes: [N, 4] - (x1, y1, x2, y2)
# scores: [N] - confianÃ§a
# landmarks: [N, 10] - 5 pontos (x,y)
```

### Processamento em Lote

```python
import glob

image_paths = glob.glob('images/*.jpg')

for img_path in image_paths:
    image = cv2.imread(img_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    bboxes, scores, landmarks = detector.detect_faces(image_rgb)
    
    # Processar resultados...
```

---

## ğŸ”¬ Detalhes TÃ©cnicos

### Arquiteturas das Redes

#### P-Net (Proposal Network)
```
Input: 12x12x3
Conv1: 10 filters, 3x3, stride=1
PReLU + MaxPool 2x2
Conv2: 16 filters, 3x3, stride=1
PReLU
Conv3: 32 filters, 3x3, stride=1
PReLU
Outputs:
  - Classification: 2 classes
  - BBox Regression: 4 offsets
  - Landmarks: 10 coordinates
```

**ParÃ¢metros:** ~31,000

#### R-Net (Refinement Network)
```
Input: 24x24x3
Conv1: 28 filters, 3x3, stride=1
PReLU + MaxPool 3x3
Conv2: 48 filters, 3x3, stride=1
PReLU + MaxPool 3x3
Conv3: 64 filters, 2x2, stride=1
PReLU
FC1: 128 units
PReLU
Outputs (FC):
  - Classification: 2 classes
  - BBox Regression: 4 offsets
  - Landmarks: 10 coordinates
```

**ParÃ¢metros:** ~98,000

#### O-Net (Output Network)
```
Input: 48x48x3
Conv1: 32 filters, 3x3, stride=1
PReLU + MaxPool 3x3
Conv2: 64 filters, 3x3, stride=1
PReLU + MaxPool 3x3
Conv3: 64 filters, 3x3, stride=1
PReLU + MaxPool 2x2
Conv4: 128 filters, 2x2, stride=1
PReLU
FC1: 256 units
PReLU
Outputs (FC):
  - Classification: 2 classes
  - BBox Regression: 4 offsets
  - Landmarks: 10 coordinates
```

**ParÃ¢metros:** ~386,000

### Loss Function Multi-tarefa

```
L = Î±â‚ * L_cls + Î±â‚‚ * L_box + Î±â‚ƒ * L_landmark

onde:
- L_cls: Cross-Entropy Loss (classificaÃ§Ã£o face/nÃ£o-face)
- L_box: MSE Loss (regressÃ£o de bounding box)
- L_landmark: MSE Loss (localizaÃ§Ã£o de landmarks)
- Î±â‚, Î±â‚‚, Î±â‚ƒ: pesos das tarefas

P-Net/R-Net: Î±â‚=1.0, Î±â‚‚=0.5, Î±â‚ƒ=0.5
O-Net: Î±â‚=1.0, Î±â‚‚=0.5, Î±â‚ƒ=1.0 (MAIOR peso para landmarks)
```

### Online Hard Sample Mining

**Algoritmo:**
```
1. Forward pass em TODO o batch
2. Calcular loss individual para cada sample
3. Ordenar losses em ordem decrescente
4. Selecionar top 70% como "hard samples"
5. Backward pass APENAS nos hard samples
```

**BenefÃ­cios:**
- ConvergÃªncia 2-3x mais rÃ¡pida
- Melhor generalizaÃ§Ã£o
- Sem necessidade de seleÃ§Ã£o manual
- Adaptativo ao treinamento

### Tipos de Samples

| Tipo | IoU | Uso | Loss Aplicada |
|------|-----|-----|---------------|
| Negative | < 0.3 | ClassificaÃ§Ã£o | Classification |
| Positive | > 0.65 | Cls + BBox | Classification + BBox |
| Part | 0.4-0.65 | Cls + BBox | Classification + BBox |
| Landmark | N/A | Landmarks | Landmark |

---

## ğŸ“Š Resultados Esperados

### Benchmarks

#### FDDB (Face Detection Data Set and Benchmark)
- **True Positive Rate @ 1000 FP:** ~95%
- **ComparaÃ§Ã£o:** Superior a Viola-Jones, DPM, ACF

#### WIDER FACE
- **Easy:** ~94%
- **Medium:** ~93%
- **Hard:** ~85%

#### AFLW (Annotated Facial Landmarks in the Wild)
- **Mean Error (normalized):** ~1.5%

### Performance Computacional

| Hardware | FPS | LatÃªncia |
|----------|-----|----------|
| Nvidia Titan Black | 99 | 10ms |
| CPU (2.60GHz) | 16 | 62ms |
| Nvidia RTX 3090 | ~150 | 6-7ms |

### Curvas de Treinamento TÃ­picas

**P-Net (30 epochs):**
- Loss inicial: ~2.5
- Loss final: ~0.3-0.5
- Melhor epoch: ~25

**R-Net (25 epochs):**
- Loss inicial: ~1.8
- Loss final: ~0.25-0.4

**O-Net (25 epochs):**
- Loss inicial: ~1.5
- Loss final: ~0.2-0.35

---

## ğŸ› Troubleshooting

### Erro: "CUDA out of memory"
**SoluÃ§Ã£o:**
- Reduzir batch size em `config.py`
- P-Net: 512 â†’ 256
- R-Net: 256 â†’ 128
- O-Net: 128 â†’ 64

### Erro: "Arquivo de anotaÃ§Ãµes nÃ£o encontrado"
**SoluÃ§Ã£o:**
- Verificar paths em `config.py`
- Executar `python main.py --mode prepare --stage <stage>`

### ConvergÃªncia lenta
**SoluÃ§Ãµes:**
- Verificar se hard sample mining estÃ¡ ativado
- Aumentar learning rate: 0.001 â†’ 0.002
- Usar learning rate schedule (jÃ¡ implementado)

### Baixa qualidade de detecÃ§Ã£o
**Causas comuns:**
- Dados insuficientes ou desbalanceados
- Treinamento nÃ£o convergiu
- Thresholds inadequados

**SoluÃ§Ãµes:**
- Gerar mais dados
- Treinar por mais Ã©pocas
- Ajustar thresholds em `config.py`

---

## ğŸ“š ReferÃªncias

**Paper Original:**
```
Zhang, K., Zhang, Z., Li, Z., & Qiao, Y. (2016).
Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks.
IEEE Signal Processing Letters, 23(10), 1499-1503.
```

**Datasets:**
- WIDER FACE: http://shuoyang1213.me/WIDERFACE/
- CelebA: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html
- FDDB: http://vis-www.cs.umass.edu/fddb/
- AFLW: https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/

---

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido para fins educacionais e de pesquisa.

---

**Desenvolvido para pesquisa acadÃªmica em Reconhecimento Facial** ğŸ“